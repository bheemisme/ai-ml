{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch import Tensor\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_FOLDER = Path(\"data/rice_leaf_diseases_dataset\")\n",
    "DATASET_FOLDER.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\"image\": [], \"label\": []}\n",
    "for root, dir, file in os.walk(DATASET_FOLDER):\n",
    "    if len(file) > 0:\n",
    "        for f in file:\n",
    "            p = Path(root) / f\n",
    "            df[\"image\"].append(str(p))\n",
    "            df[\"label\"].append(p.parent.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4684, 1) (4684, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(df)\n",
    "y = df.loc[:, [\"label\"]]\n",
    "X = df.drop([\"label\"],axis=1)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3747, 1) (3747, 1) (937, 1) (937, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CMYKToRGB(object):\n",
    "    def __call__(self, img: Image.Image) -> Image.Image:\n",
    "        if img.mode == 'RGBA' or img.mode == \"CMYK\":\n",
    "            img = img.convert('RGB')\n",
    "        \n",
    "        \n",
    "        return img\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    CMYKToRGB(),\n",
    "    transforms.PILToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, X: pd.DataFrame, y: pd.DataFrame, transform=transform) -> None:\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[Tensor, str]:\n",
    "        p = str(self.X.iloc[index, 0])\n",
    "        label = str(self.y.iloc[index, 0])\n",
    "        \n",
    "        img: Tensor = self.transform(Image.open(p)) # type: ignore\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 1, 0, 2])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class_names = [\"cat\", \"dog\", \"fish\", \"dog\", \"cat\", \"fish\"]\n",
    "lbl = LabelEncoder()\n",
    "\n",
    "class_indices = lbl.fit_transform(class_names)\n",
    "\n",
    "type(class_indices)\n",
    "\n",
    "torch.from_numpy(class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118, 32, 3, 300, 300)\n",
      "(30, 32, 3, 300, 300)\n"
     ]
    }
   ],
   "source": [
    "IN_CHANNELS = 3\n",
    "IMAGE_WIDTH = 300\n",
    "IMAGE_HEIGHT = 300\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE  = 32\n",
    "TOTAL_TRAIN_BATCHES = y_train.shape[0] // TRAIN_BATCH_SIZE + \\\n",
    "    (1 if y_train.shape[0] % TRAIN_BATCH_SIZE != 0 else 0)\n",
    "TOTAL_TEST_BATCHES = y_test.shape[0] // TEST_BATCH_SIZE + \\\n",
    "    (1 if y_test.shape[0] % TEST_BATCH_SIZE != 0 else 0)\n",
    "\n",
    "print((TOTAL_TRAIN_BATCHES, TRAIN_BATCH_SIZE, IN_CHANNELS, IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "print((TOTAL_TEST_BATCHES, TEST_BATCH_SIZE, IN_CHANNELS, IMAGE_WIDTH, IMAGE_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(X_train, y_train)\n",
    "test_dataset = CustomImageDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, TRAIN_BATCH_SIZE, num_workers=2)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, TEST_BATCH_SIZE, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_cnn(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=53290, out_features=10, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=10, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class model_cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=10, kernel_size=4, stride=2), # 300 * 300\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1), # 149 * 149\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 74 * 74\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(10*73*73, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 3)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block2(self.block1(x))\n",
    "\n",
    "\n",
    "model_0 = model_cnn()\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "model_cnn                                [1, 3]                    --\n",
       "├─Sequential: 1-1                        [1, 10, 73, 73]           --\n",
       "│    └─Conv2d: 2-1                       [1, 10, 149, 149]         490\n",
       "│    └─ReLU: 2-2                         [1, 10, 149, 149]         --\n",
       "│    └─Conv2d: 2-3                       [1, 10, 147, 147]         910\n",
       "│    └─ReLU: 2-4                         [1, 10, 147, 147]         --\n",
       "│    └─MaxPool2d: 2-5                    [1, 10, 73, 73]           --\n",
       "├─Sequential: 1-2                        [1, 3]                    --\n",
       "│    └─Flatten: 2-6                      [1, 53290]                --\n",
       "│    └─Linear: 2-7                       [1, 10]                   532,910\n",
       "│    └─ReLU: 2-8                         [1, 10]                   --\n",
       "│    └─Linear: 2-9                       [1, 10]                   110\n",
       "│    └─ReLU: 2-10                        [1, 10]                   --\n",
       "│    └─Linear: 2-11                      [1, 3]                    33\n",
       "==========================================================================================\n",
       "Total params: 534,453\n",
       "Trainable params: 534,453\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 31.08\n",
       "==========================================================================================\n",
       "Input size (MB): 1.08\n",
       "Forward/backward pass size (MB): 3.50\n",
       "Params size (MB): 2.14\n",
       "Estimated Total Size (MB): 6.72\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "\n",
    "torchinfo.summary(model_0,input_size=[1,IN_CHANNELS,IMAGE_WIDTH,IMAGE_HEIGHT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "accuracy = Accuracy(task=\"multiclass\",num_classes=3)\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(),lr=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778d20646fff4e54bb009858c4aa6add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | train_loss: 22068.753537854907 | train_acc: 0.35478460788726807 | test_loss: 1.1179152806599935 | test_acc: 0.32766202092170715\n",
      "epoch: 2 | train_loss: 1.1058746626821614 | train_acc: 0.3539901077747345 | test_loss: 1.1181634823481241 | test_acc: 0.33981481194496155\n",
      "epoch: 3 | train_loss: 1.1062543816485648 | train_acc: 0.3481638431549072 | test_loss: 1.1184303959210713 | test_acc: 0.33564814925193787\n",
      "epoch: 4 | train_loss: 1.1064071028919544 | train_acc: 0.3481638431549072 | test_loss: 1.118838628133138 | test_acc: 0.33298608660697937\n",
      "epoch: 5 | train_loss: 1.1064857183876684 | train_acc: 0.3481638431549072 | test_loss: 1.1186490416526795 | test_acc: 0.33298608660697937\n",
      "epoch: 6 | train_loss: 1.1065325252080367 | train_acc: 0.3478989899158478 | test_loss: 1.1184845964113872 | test_acc: 0.33298608660697937\n",
      "epoch: 7 | train_loss: 1.1065632690817624 | train_acc: 0.34604519605636597 | test_loss: 1.1187743663787841 | test_acc: 0.33298608660697937\n",
      "epoch: 8 | train_loss: 1.1065848055532423 | train_acc: 0.34604519605636597 | test_loss: 1.1165086070696513 | test_acc: 0.338310182094574\n",
      "epoch: 9 | train_loss: 1.1066006502862704 | train_acc: 0.34604519605636597 | test_loss: 1.119890328248342 | test_acc: 0.32766202092170715\n",
      "epoch: 10 | train_loss: 1.1066126490043382 | train_acc: 0.34736934304237366 | test_loss: 1.117010776201884 | test_acc: 0.33564814925193787\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "torch.manual_seed(42)\n",
    "epochs = 10\n",
    "lbl = LabelEncoder()\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model_0.train()\n",
    "\n",
    "        X = X.type(torch.float32)\n",
    "        y_indices = torch.from_numpy(lbl.fit_transform(y))\n",
    "\n",
    "        y_logits = model_0(X)\n",
    "        y_preds = torch.softmax(y_logits, dim=1)\n",
    "\n",
    "        l = loss_fn(y_logits, y_indices)\n",
    "        train_loss += l.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        l.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_acc += accuracy(y_preds, y_indices)\n",
    "\n",
    "    train_loss = train_loss / len(train_dataloader)\n",
    "    train_acc = train_acc / len(train_dataloader)\n",
    "\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    for batch, (X, y) in enumerate(test_dataloader):\n",
    "        model_0.eval()\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            X = X.type(torch.float32)\n",
    "            y_test_indices = torch.from_numpy(lbl.fit_transform(y))\n",
    "\n",
    "            y_test_logits = model_0(X)\n",
    "            y_test_preds = torch.softmax(y_test_logits, dim=1)\n",
    "\n",
    "            l = loss_fn(y_test_logits, y_test_indices)\n",
    "            test_loss += l.item()\n",
    "            test_acc += accuracy(y_test_preds, y_test_indices)\n",
    "\n",
    "    test_loss_1 = test_loss / len(test_dataloader)\n",
    "    test_acc_1 = test_acc / len(test_dataloader)\n",
    "\n",
    "    print(f\"epoch: {epoch} | train_loss: {train_loss} | train_acc: {train_acc} | test_loss: {test_loss_1} | test_acc: {test_acc_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "torchvision.models.efficientnet_b0()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
